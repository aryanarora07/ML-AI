{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMm2HNahYiH7bIjlSBbHMx/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aryanarora07/ML-AI/blob/main/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RpqWp_r-6mD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from glob import glob\n",
        "import time\n",
        "from PIL import Image\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Check for GPU availability\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "\n",
        "\n",
        "def load_and_preprocess_data(data_dir, img_shape=(128, 128, 3), batch_size=64):\n",
        "    \"\"\"\n",
        "    Load and preprocess images from a directory\n",
        "    \"\"\"\n",
        "    print(\"Loading and preprocessing dataset...\")\n",
        "\n",
        "    # Create a dataset from the directory\n",
        "    try:\n",
        "        dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "            data_dir,\n",
        "            label_mode=None,  # We don't need labels for GAN\n",
        "            image_size=(img_shape[0], img_shape[1]),\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True\n",
        "        )\n",
        "    except Exception as e:\n",
        "        # If the above fails (e.g., no subdirectories), try with direct image loading\n",
        "        print(f\"Directory loading failed: {e}\")\n",
        "        print(\"Attempting to load from root directory...\")\n",
        "\n",
        "        # Create a directory structure expected by the loader\n",
        "        new_dir = data_dir + \"_structured\"\n",
        "        os.makedirs(new_dir + \"/images\", exist_ok=True)\n",
        "\n",
        "        # Move images to new structure\n",
        "        for ext in ['*.jpg', '*.jpeg', '*.png']:\n",
        "            for file in glob(os.path.join(data_dir, ext)):\n",
        "                os.system(f\"cp '{file}' '{new_dir}/images/'\")\n",
        "\n",
        "        dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "            new_dir,\n",
        "            label_mode=None,\n",
        "            image_size=(img_shape[0], img_shape[1]),\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "    # Normalize images to [0, 1] range\n",
        "    normalization_layer = layers.Rescaling(1./255)\n",
        "    dataset = dataset.map(lambda x: normalization_layer(x))\n",
        "\n",
        "    # Use prefetch to optimize performance\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "def manual_load_data(data_dir, img_shape=(128, 128), batch_size=64):\n",
        "    \"\"\"\n",
        "    Manually load and preprocess images from a directory\n",
        "    \"\"\"\n",
        "    print(\"Manually loading dataset...\")\n",
        "    image_paths = glob(os.path.join(data_dir, \"**/*.jpg\"), recursive=True) + \\\n",
        "                  glob(os.path.join(data_dir, \"**/*.jpeg\"), recursive=True) + \\\n",
        "                  glob(os.path.join(data_dir, \"**/*.png\"), recursive=True)\n",
        "\n",
        "    if not image_paths:\n",
        "        raise ValueError(f\"No images found in {data_dir}\")\n",
        "\n",
        "    print(f\"Found {len(image_paths)} images\")\n",
        "\n",
        "    # Create a smaller dataset if there are too many images (for testing)\n",
        "    if len(image_paths) > 1000:\n",
        "        print(\"Using a subset of 1000 images for faster processing\")\n",
        "        np.random.shuffle(image_paths)\n",
        "        image_paths = image_paths[:1000]\n",
        "\n",
        "    # Function to load and preprocess a single image\n",
        "    def preprocess_image(img_path):\n",
        "        try:\n",
        "            img = load_img(img_path, target_size=img_shape)\n",
        "            img_array = img_to_array(img)\n",
        "            # Normalize to [0, 1]\n",
        "            img_array = img_array / 255.0\n",
        "            return img_array\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {img_path}: {e}\")\n",
        "            # Return a blank image in case of error\n",
        "            return np.zeros(img_shape + (3,))\n",
        "\n",
        "    # Load and preprocess all images with a progress bar\n",
        "    print(\"Loading images...\")\n",
        "    images = []\n",
        "    for path in tqdm(image_paths):\n",
        "        images.append(preprocess_image(path))\n",
        "\n",
        "    images = np.array(images)\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(images)\n",
        "    dataset = dataset.shuffle(buffer_size=len(images))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# @title Show sample images\n",
        "def show_sample_images(dataset, n_samples=25):\n",
        "    \"\"\"\n",
        "    Display sample images from the dataset\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    # Get a batch from the dataset\n",
        "    for images in dataset.take(1):\n",
        "        for i in range(min(n_samples, len(images))):\n",
        "            plt.subplot(5, 5, i + 1)\n",
        "            plt.imshow(images[i])\n",
        "            plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ====== GAN Architecture ======\n",
        "# @title Generator and Discriminator models\n",
        "\n",
        "def build_generator(latent_dim, output_shape):\n",
        "    \"\"\"\n",
        "    Build the generator model\n",
        "    \"\"\"\n",
        "    model = models.Sequential(name=\"Generator\")\n",
        "\n",
        "    # Starting with a dense layer that takes the latent vector\n",
        "    n_nodes = 8 * 8 * 256  # Foundation for 8x8 feature maps\n",
        "    model.add(layers.Dense(n_nodes, input_dim=latent_dim))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Reshape((8, 8, 256)))\n",
        "\n",
        "    # Upsampling blocks to reach target size\n",
        "    # First upsampling: 8x8 -> 16x16\n",
        "    model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    # Second upsampling: 16x16 -> 32x32\n",
        "    model.add(layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    # Third upsampling: 32x32 -> 64x64\n",
        "    model.add(layers.Conv2DTranspose(32, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    # Fourth upsampling: 64x64 -> 128x128 (if needed based on target size)\n",
        "    if output_shape[0] >= 128:\n",
        "        model.add(layers.Conv2DTranspose(16, (4, 4), strides=(2, 2), padding='same'))\n",
        "        model.add(layers.LeakyReLU(alpha=0.2))\n",
        "        model.add(layers.BatchNormalization())\n",
        "\n",
        "    # Output layer with tanh activation to get values in [-1, 1]\n",
        "    model.add(layers.Conv2D(output_shape[2], (3, 3), padding='same', activation='tanh'))\n",
        "\n",
        "    return model\n",
        "\n",
        "def build_discriminator(input_shape):\n",
        "    \"\"\"\n",
        "    Build the discriminator model\n",
        "    \"\"\"\n",
        "    model = models.Sequential(name=\"Discriminator\")\n",
        "\n",
        "    # First convolutional block\n",
        "    model.add(layers.Conv2D(32, (3, 3), strides=(2, 2), padding='same', input_shape=input_shape))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    # Second convolutional block\n",
        "    model.add(layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    # Third convolutional block\n",
        "    model.add(layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    # Fourth convolutional block\n",
        "    model.add(layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    # Flatten and output\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define GAN\n",
        "def build_gan(generator, discriminator):\n",
        "    \"\"\"\n",
        "    Combine generator and discriminator into a GAN\n",
        "    \"\"\"\n",
        "    # For training the combined model, we don't want to update the discriminator weights\n",
        "    discriminator.trainable = False\n",
        "\n",
        "    model = models.Sequential(name=\"GAN\")\n",
        "    model.add(generator)\n",
        "    model.add(discriminator)\n",
        "\n",
        "    return model\n",
        "\n",
        "# ====== Training Functions ======\n",
        "# @title GAN Training Functions\n",
        "\n",
        "def save_generated_images(generator, epoch, latent_dim, directory, n_samples=16):\n",
        "    \"\"\"\n",
        "    Generate and save images\n",
        "    \"\"\"\n",
        "    # Generate images\n",
        "    noise = tf.random.normal([n_samples, latent_dim])\n",
        "    generated_images = generator(noise, training=False)\n",
        "\n",
        "    # Scale from [-1,1] to [0,1]\n",
        "    generated_images = (generated_images + 1) / 2.0\n",
        "\n",
        "    # Plot images\n",
        "    fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
        "\n",
        "    for i, ax in enumerate(axes.flatten()):\n",
        "        if i < n_samples:\n",
        "            # Plot image\n",
        "            ax.imshow(generated_images[i])\n",
        "            ax.axis('off')\n",
        "\n",
        "    # Save plot (make sure directory exists)\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{directory}/epoch_{epoch}.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # Also display in the notebook\n",
        "    if epoch % 10 == 0 or epoch == \"final\":\n",
        "        # Display the same images in the notebook\n",
        "        fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
        "\n",
        "        for i, ax in enumerate(axes.flatten()):\n",
        "            if i < n_samples:\n",
        "                ax.imshow(generated_images[i])\n",
        "                ax.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "def train_gan(generator, discriminator, gan, dataset, latent_dim, n_epochs=100, n_batch=64, save_interval=10):\n",
        "    \"\"\"\n",
        "    Train the GAN\n",
        "    \"\"\"\n",
        "    # Prepare directories for saving samples\n",
        "    sample_dir = \"/content/generated_samples\"\n",
        "    os.makedirs(sample_dir, exist_ok=True)\n",
        "\n",
        "    # Create checkpoint directory\n",
        "    checkpoint_dir = \"/content/checkpoints\"\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    # Calculate steps per epoch (might be inaccurate for unknown dataset sizes)\n",
        "    try:\n",
        "        steps_per_epoch = len(dataset)\n",
        "    except:\n",
        "        # If dataset doesn't have len, make an estimate\n",
        "        steps_per_epoch = 100  # Arbitrary default\n",
        "\n",
        "    # Progress visualization\n",
        "    loss_history = {\n",
        "        'disc_loss': [],\n",
        "        'gen_loss': []\n",
        "    }\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(n_epochs):\n",
        "        start_time = time.time()\n",
        "        disc_loss_total = 0\n",
        "        gen_loss_total = 0\n",
        "\n",
        "        # Create progress bar\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
        "        progress_bar = tqdm(total=steps_per_epoch, desc=f\"Training\")\n",
        "\n",
        "        # Train on batches\n",
        "        batch_count = 0\n",
        "        for real_images in dataset:\n",
        "            # Get batch size (might be different for last batch)\n",
        "            batch_size = tf.shape(real_images)[0]\n",
        "            batch_count += 1\n",
        "\n",
        "            # Skip small batches\n",
        "            if batch_size < 8:\n",
        "                continue\n",
        "\n",
        "            # Generate random noise for G\n",
        "            noise = tf.random.normal([batch_size, latent_dim])\n",
        "\n",
        "            # Generate fake images\n",
        "            fake_images = generator(noise, training=True)\n",
        "\n",
        "            # Create labels for real and fake images\n",
        "            real_labels = tf.ones((batch_size, 1)) * 0.9  # Using label smoothing (0.9 instead of 1)\n",
        "            fake_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "            # Add random noise to labels for robustness\n",
        "            real_labels += 0.05 * tf.random.uniform((batch_size, 1))\n",
        "            fake_labels += 0.05 * tf.random.uniform((batch_size, 1))\n",
        "\n",
        "            # Train discriminator\n",
        "            with tf.GradientTape() as disc_tape:\n",
        "                # Predictions\n",
        "                real_predictions = discriminator(real_images, training=True)\n",
        "                fake_predictions = discriminator(fake_images, training=True)\n",
        "\n",
        "                # Calculate losses\n",
        "                real_loss = tf.keras.losses.binary_crossentropy(real_labels, real_predictions)\n",
        "                fake_loss = tf.keras.losses.binary_crossentropy(fake_labels, fake_predictions)\n",
        "                disc_loss = real_loss + fake_loss\n",
        "\n",
        "            # Apply gradients\n",
        "            disc_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "            discriminator.optimizer.apply_gradients(zip(disc_gradients, discriminator.trainable_variables))\n",
        "\n",
        "            # Update the generator\n",
        "            noise = tf.random.normal([batch_size, latent_dim])\n",
        "\n",
        "            # Labels for generated images (telling G we want D to think these are real)\n",
        "            misleading_labels = tf.ones((batch_size, 1))\n",
        "\n",
        "            with tf.GradientTape() as gen_tape:\n",
        "                # Generate images\n",
        "                fake_images = generator(noise, training=True)\n",
        "                # Get predictions\n",
        "                predictions = discriminator(fake_images, training=True)\n",
        "                # Calculate loss\n",
        "                gen_loss = tf.keras.losses.binary_crossentropy(misleading_labels, predictions)\n",
        "\n",
        "            # Apply gradients\n",
        "            gen_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "            generator.optimizer.apply_gradients(zip(gen_gradients, generator.trainable_variables))\n",
        "\n",
        "            # Track progress\n",
        "            current_disc_loss = tf.reduce_mean(disc_loss)\n",
        "            current_gen_loss = tf.reduce_mean(gen_loss)\n",
        "            disc_loss_total += current_disc_loss\n",
        "            gen_loss_total += current_gen_loss\n",
        "\n",
        "            # Update progress bar\n",
        "            progress_bar.update(1)\n",
        "            progress_bar.set_postfix({\n",
        "                'D_loss': f\"{current_disc_loss:.4f}\",\n",
        "                'G_loss': f\"{current_gen_loss:.4f}\"\n",
        "            })\n",
        "\n",
        "            # Stop if we've reached the estimated steps (avoid infinite loops)\n",
        "            if batch_count >= steps_per_epoch:\n",
        "                break\n",
        "\n",
        "        # Close progress bar\n",
        "        progress_bar.close()\n",
        "\n",
        "        # Calculate average loss per epoch\n",
        "        avg_disc_loss = disc_loss_total / batch_count\n",
        "        avg_gen_loss = gen_loss_total / batch_count\n",
        "\n",
        "        # Store losses for plotting\n",
        "        loss_history['disc_loss'].append(avg_disc_loss)\n",
        "        loss_history['gen_loss'].append(avg_gen_loss)\n",
        "\n",
        "        # Print epoch summary\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs} - {time.time()-start_time:.2f}s - D Loss: {avg_disc_loss:.4f}, G Loss: {avg_gen_loss:.4f}\")\n",
        "\n",
        "        # Save samples\n",
        "        if (epoch + 1) % save_interval == 0 or epoch == 0:\n",
        "            save_generated_images(generator, epoch+1, latent_dim, sample_dir)\n",
        "\n",
        "        # Save model periodically\n",
        "        if (epoch + 1) % 20 == 0:\n",
        "            generator.save(f\"{checkpoint_dir}/generator_epoch_{epoch+1}.h5\")\n",
        "            discriminator.save(f\"{checkpoint_dir}/discriminator_epoch_{epoch+1}.h5\")\n",
        "\n",
        "            # Save to Google Drive for persistence\n",
        "            generator.save(f\"/content/drive/MyDrive/GAN_Models/generator_epoch_{epoch+1}.h5\")\n",
        "\n",
        "    # Plot loss history\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(loss_history['disc_loss'], label='Discriminator')\n",
        "    plt.plot(loss_history['gen_loss'], label='Generator')\n",
        "    plt.title('GAN Training Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig(f\"{sample_dir}/loss_history.png\")\n",
        "    plt.show()\n",
        "\n",
        "    return loss_history\n",
        "\n",
        "# @title Generate Art Portfolio\n",
        "\n",
        "def generate_art_portfolio(generator_path, output_dir, n_images=50, latent_dim=100, img_size=(128, 128)):\n",
        "    \"\"\"\n",
        "    Generate a portfolio of abstract art from a trained generator\n",
        "    \"\"\"\n",
        "    # Create output directory\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Load the generator\n",
        "    generator = tf.keras.models.load_model(generator_path)\n",
        "\n",
        "    # Generate images with progress bar\n",
        "    print(f\"Generating {n_images} images...\")\n",
        "    for i in tqdm(range(n_images)):\n",
        "        # Generate random noise\n",
        "        noise = tf.random.normal([1, latent_dim])\n",
        "\n",
        "        # Generate image\n",
        "        generated_image = generator(noise, training=False)\n",
        "\n",
        "        # Scale from [-1,1] to [0,1]\n",
        "        generated_image = (generated_image + 1) / 2.0\n",
        "\n",
        "        # Convert to numpy array\n",
        "        img_array = generated_image[0].numpy()\n",
        "\n",
        "        # Convert to PIL image and save\n",
        "        img = Image.fromarray((img_array * 255).astype(np.uint8))\n",
        "        img.save(f\"{output_dir}/abstract_art_{i+1}.png\")\n",
        "\n",
        "    # Display a sample of generated images\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    sample_indices = np.random.choice(n_images, min(25, n_images), replace=False) + 1\n",
        "\n",
        "    for i, idx in enumerate(sample_indices):\n",
        "        if i < 25:  # Show up to 25 images\n",
        "            img = Image.open(f\"{output_dir}/abstract_art_{idx}.png\")\n",
        "            plt.subplot(5, 5, i + 1)\n",
        "            plt.imshow(np.array(img))\n",
        "            plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Generated {n_images} images in {output_dir}\")\n",
        "    print(f\"Files are also saved to your Google Drive at: {output_dir}\")"
      ]
    }
  ]
}